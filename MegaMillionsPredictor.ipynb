{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPloFpwZGxYhcJM0GirZKL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonvthvn90/AndroidApp/blob/main/MegaMillionsPredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Jh8wqFZs94b"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog, messagebox\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "Gi7y0WFjtBZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LotteryPredictor:\n",
        "    def __init__(self, master):\n",
        "        self.master = master\n",
        "        master.title(\"Mega Millions Predictor\")\n",
        "\n",
        "        self.label = tk.Label(master, text=\"Upload your Mega Millions results text file:\")\n",
        "        self.label.pack()\n",
        "\n",
        "        self.upload_button = tk.Button(master, text=\"Upload File\", command=self.upload_file)\n",
        "        self.upload_button.pack()\n",
        "\n",
        "        self.predict_button = tk.Button(master, text=\"Get Predictions\", command=self.make_predictions, state=tk.DISABLED)\n",
        "        self.predict_button.pack()\n",
        "\n",
        "        self.prediction_label = tk.Label(master, text=\"\", font=(\"Helvetica\", 12))\n",
        "        self.prediction_label.pack()\n",
        "\n",
        "        self.file_path = None\n",
        "        self.history_data = None"
      ],
      "metadata": {
        "id": "eim3FUiKtK7a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(self):\n",
        "        self.file_path = filedialog.askopenfilename(filetypes=[(\"Text Files\", \"*.txt\")])\n",
        "        if self.file_path:\n",
        "            messagebox.showinfo(\"File Selected\", \"File uploaded successfully!\")\n",
        "            self.history_data = self.load_data(self.file_path)  # Load historical data on upload\n",
        "            self.predict_button.config(state=tk.NORMAL)\n"
      ],
      "metadata": {
        "id": "7HMWQIlOtTK2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def make_predictions(self):\n",
        "        if self.file_path:\n",
        "            predictions = self.predict_numbers(self.history_data)\n",
        "            prediction_text = \", \".join(map(str, predictions))\n",
        "            self.prediction_label.config(text=f\"Predicted Numbers: {prediction_text}\")\n"
      ],
      "metadata": {
        "id": "8IYiM2Y7tX5H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def predict_numbers(self, data):\n",
        "        # Statistical Analysis: Descriptive statistics and frequency analysis\n",
        "        frequency_analysis = self.frequency_analysis(data)\n",
        "\n",
        "        # Moving Averages\n",
        "        moving_average = self.calculate_moving_average(data)\n",
        "\n",
        "        # Prepare features for Machine Learning\n",
        "        X, y = self.prepare_ml_data(data)\n",
        "\n",
        "        # Train Machine Learning Models\n",
        "        dt_predictions = self.train_decision_tree(X, y)\n",
        "        rf_predictions = self.train_random_forest(X, y)\n",
        "        nn_predictions = self.train_neural_network(X, y)\n",
        "\n",
        "        # Time Series Analysis with ARIMA\n",
        "        mega_ball_forecast = self.time_series_analysis(data)\n",
        "\n",
        "        # Clustering: K-Means\n",
        "        self.clustering(data)\n",
        "\n",
        "        # Predictions\n",
        "        predictions = random.sample(frequency_analysis, 5)  # Random sample of frequent numbers\n",
        "        predictions.append(int(mega_ball_forecast))  # Add Mega Ball prediction\n",
        "\n",
        "        # Evolve predictions using Genetic Algorithms\n",
        "        evolved_predictions = self.genetic_algorithm(predictions, data)  # Pass historical data for fitness evaluation\n",
        "\n",
        "        return evolved_predictions"
      ],
      "metadata": {
        "id": "FyP1DtZwte-W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def load_data(self, file_path):\n",
        "        # Load and clean the data\n",
        "        data = pd.read_csv(file_path, sep=';', header=None, names=['Date', 'Numbers', 'Mega Ball'])\n",
        "        data['Numbers'] = data['Numbers'].apply(lambda x: list(map(int, x.split(','))))\n",
        "        data['Mega Ball'] = data['Mega Ball'].apply(lambda x: int(x.split(': ')[1]))  # Extract Mega Ball number\n",
        "        return data\n"
      ],
      "metadata": {
        "id": "bXSRxUEmtsA2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def frequency_analysis(self, data):\n",
        "        # Frequency Analysis of numbers\n",
        "        flattened_numbers = [num for sublist in data['Numbers'] for num in sublist]\n",
        "        number_counts = Counter(flattened_numbers)\n",
        "        most_common_numbers = number_counts.most_common(10)\n",
        "        return [num for num, _ in most_common_numbers]\n"
      ],
      "metadata": {
        "id": "BcTpSNHFt0nM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def calculate_moving_average(self, data):\n",
        "        # Calculate moving averages for Mega Ball\n",
        "        return data['Mega Ball'].rolling(window=5).mean()\n"
      ],
      "metadata": {
        "id": "LKAW6b-Qt5Ug"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_ml_data(self, data):\n",
        "        # Prepare features and target for machine learning\n",
        "        features = []\n",
        "        targets = []\n",
        "\n",
        "        for i in range(len(data) - 1):\n",
        "            features.append(data['Numbers'].iloc[i])\n",
        "            targets.append(data['Numbers'].iloc[i + 1])\n",
        "\n",
        "        X = np.array(features)\n",
        "        y = np.array(targets)\n",
        "        return X, y\n"
      ],
      "metadata": {
        "id": "qm2Wias1t91_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def train_decision_tree(self, X, y):\n",
        "        # Train Decision Tree Classifier with hyperparameter tuning\n",
        "        param_grid = {'max_depth': [3, 5, 7, None], 'min_samples_split': [2, 5, 10]}\n",
        "        grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "        grid_search.fit(X, y)\n",
        "        return grid_search.best_estimator_.predict(X)\n"
      ],
      "metadata": {
        "id": "NByjZfLUuD7x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_random_forest(self, X, y):\n",
        "        # Train Random Forest Classifier with hyperparameter tuning\n",
        "        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, None]}\n",
        "        grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
        "        grid_search.fit(X, y)\n",
        "        return grid_search.best_estimator_.predict(X)\n"
      ],
      "metadata": {
        "id": "dD_fw1eeuKYL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def train_neural_network(self, X, y):\n",
        "        # Train Neural Network\n",
        "        nn_model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000)\n",
        "        nn_model.fit(X, y)\n",
        "        predictions = nn_model.predict(X)\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "Y9vV243SuVpA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def time_series_analysis(self, data):\n",
        "        # Apply ARIMA for time series analysis on Mega Ball\n",
        "        mega_ball_results = data['Mega Ball'].astype(int)\n",
        "        arima_model = ARIMA(mega_ball_results, order=(5, 1, 0))\n",
        "        arima_model_fit = arima_model.fit()\n",
        "        mega_ball_forecast = arima_model_fit.forecast(steps=1)\n",
        "        return mega_ball_forecast.values[0]"
      ],
      "metadata": {
        "id": "SLsJ8Xy8udzA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def clustering(self, data):\n",
        "        # Use K-Means clustering to identify patterns\n",
        "        all_numbers = np.array([num for sublist in data['Numbers'] for num in sublist]).reshape(-1, 1)\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "        kmeans.fit(all_numbers)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(all_numbers, np.zeros_like(all_numbers), c=kmeans.labels_, cmap='viridis', marker='o')\n",
        "        plt.title('K-Means Clustering of Mega Millions Numbers')\n",
        "        plt.xlabel('Mega Millions Numbers')\n",
        "        plt.ylabel('Clusters')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "QATR5RlMuhtj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def genetic_algorithm(self, predictions, historical_data):\n",
        "        # Basic Genetic Algorithm for evolving predictions\n",
        "        population_size = 100\n",
        "        generations = 50"
      ],
      "metadata": {
        "id": "ukiGIbGWumVW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genetic_algorithm(self, predictions, historical_data):\n",
        "    # Basic Genetic Algorithm for evolving predictions\n",
        "    population_size = 100\n",
        "    generations = 50\n",
        "    # Generate initial population\n",
        "    population = [random.sample(range(1, 71), 5) for _ in range(population_size)]  # Mega Millions ranges from 1 to 70\n",
        "\n",
        "    for _ in range(generations):\n",
        "        # Calculate fitness based on historical data\n",
        "        fitness = [self.calculate_fitness(individual, historical_data) for individual in population]\n",
        "\n",
        "        # Selection: choose the best individuals\n",
        "        selected_indices = np.argsort(fitness)[-20:]  # Select top 20 individuals\n",
        "        selected = [population[i] for i in selected_indices]\n",
        "\n",
        "        # Crossover: create new individuals\n",
        "        next_generation = []\n",
        "        while len(next_generation) < population_size:\n",
        "            parent1, parent2 = random.sample(selected, 2)\n",
        "            crossover_point = random.randint(1, 4)\n",
        "            child = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "            next_generation.append(child)\n",
        "\n",
        "        population = next_generation\n",
        "\n",
        "    best_individual = population[np.argmax(fitness)]\n",
        "    return best_individual\n",
        "\n",
        "def calculate_fitness(self, individual, historical_data): # Adjusted indentation to align with genetic_algorithm\n",
        "    # Calculate fitness based on matching historical results\n",
        "    match_count = 0\n",
        "    for _, row in historical_data.iterrows():\n",
        "        if set(individual).intersection(set(row['Numbers'])):\n",
        "            match_count += 1\n",
        "    return match_count  # Higher score for more matches"
      ],
      "metadata": {
        "id": "ZIhe4-F9wZiP"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}