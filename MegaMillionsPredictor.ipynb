{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK6hwFfgPjV+EmN8ugtt1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonvthvn90/AndroidApp/blob/main/MegaMillionsPredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gIsyus_zBP3",
        "outputId": "eb8f6380-0296-4210-e6f9-7b42d481aedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn statsmodels matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8Jh8wqFZs94b"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog, messagebox\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "Gi7y0WFjtBZn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LotteryPredictor:\n",
        "    def __init__(self, master):\n",
        "        self.master = master\n",
        "        master.title(\"Mega Millions Predictor\")\n",
        "\n",
        "        self.label = tk.Label(master, text=\"Upload your Mega Millions results text file:\")\n",
        "        self.label.pack()\n",
        "\n",
        "        self.upload_button = tk.Button(master, text=\"Upload File\", command=self.upload_file)\n",
        "        self.upload_button.pack()\n",
        "\n",
        "        self.predict_button = tk.Button(master, text=\"Get Predictions\", command=self.make_predictions, state=tk.DISABLED)\n",
        "        self.predict_button.pack()\n",
        "\n",
        "        self.prediction_label = tk.Label(master, text=\"\", font=(\"Helvetica\", 12))\n",
        "        self.prediction_label.pack()\n",
        "\n",
        "        self.file_path = None\n",
        "        self.history_data = None"
      ],
      "metadata": {
        "id": "eim3FUiKtK7a"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(self):\n",
        "        self.file_path = filedialog.askopenfilename(filetypes=[(\"Text Files\", \"*.txt\")])\n",
        "        if self.file_path:\n",
        "            messagebox.showinfo(\"File Selected\", \"File uploaded successfully!\")\n",
        "            self.history_data = self.load_data(self.file_path)  # Load historical data on upload\n",
        "            self.predict_button.config(state=tk.NORMAL)\n"
      ],
      "metadata": {
        "id": "7HMWQIlOtTK2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(self):\n",
        "        self.file_path = filedialog.askopenfilename(filetypes=[(\"Text Files\", \"*.txt\")])\n",
        "        if self.file_path:\n",
        "            messagebox.showinfo(\"File Selected\", \"File uploaded successfully!\")\n",
        "            self.history_data = self.load_data(self.file_path)  # Load historical data on upload\n",
        "            self.predict_button.config(state=tk.NORMAL)\n"
      ],
      "metadata": {
        "id": "8IYiM2Y7tX5H"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def predict_numbers(self, data):\n",
        "        # Statistical Analysis: Descriptive statistics and frequency analysis\n",
        "        frequency_analysis = self.frequency_analysis(data)\n",
        "\n",
        "        # Moving Averages\n",
        "        moving_average = self.calculate_moving_average(data)\n",
        "\n",
        "        # Prepare features for Machine Learning\n",
        "        X, y = self.prepare_ml_data(data)\n",
        "\n",
        "        # Train Machine Learning Models\n",
        "        dt_predictions = self.train_decision_tree(X, y)\n",
        "        rf_predictions = self.train_random_forest(X, y)\n",
        "        nn_predictions = self.train_neural_network(X, y)\n",
        "\n",
        "        # Time Series Analysis with ARIMA\n",
        "        mega_ball_forecast = self.time_series_analysis(data)\n",
        "\n",
        "        # Clustering: K-Means\n",
        "        self.clustering(data)\n",
        "\n",
        "        # Predictions\n",
        "        predictions = random.sample(frequency_analysis, 5)  # Random sample of frequent numbers\n",
        "        predictions.append(int(mega_ball_forecast))  # Add Mega Ball prediction\n",
        "\n",
        "        # Evolve predictions using Genetic Algorithms\n",
        "        evolved_predictions = self.genetic_algorithm(predictions, data)  # Pass historical data for fitness evaluation\n",
        "\n",
        "        return evolved_predictions"
      ],
      "metadata": {
        "id": "FyP1DtZwte-W"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def load_data(self, file_path):\n",
        "        # Load and clean the data\n",
        "        data = pd.read_csv(file_path, sep=';', header=None, names=['Date', 'Numbers', 'Mega Ball'])\n",
        "        data['Numbers'] = data['Numbers'].apply(lambda x: list(map(int, x.split(','))))\n",
        "        data['Mega Ball'] = data['Mega Ball'].apply(lambda x: int(x.split(': ')[1]))  # Extract Mega Ball number\n",
        "        return data\n"
      ],
      "metadata": {
        "id": "bXSRxUEmtsA2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def frequency_analysis(self, data):\n",
        "        # Frequency Analysis of numbers\n",
        "        flattened_numbers = [num for sublist in data['Numbers'] for num in sublist]\n",
        "        number_counts = Counter(flattened_numbers)\n",
        "        most_common_numbers = number_counts.most_common(10)\n",
        "        return [num for num, _ in most_common_numbers]\n"
      ],
      "metadata": {
        "id": "BcTpSNHFt0nM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def calculate_moving_average(self, data):\n",
        "        # Calculate moving averages for Mega Ball\n",
        "        return data['Mega Ball'].rolling(window=5).mean()\n"
      ],
      "metadata": {
        "id": "LKAW6b-Qt5Ug"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_ml_data(self, data):\n",
        "        # Prepare features and target for machine learning\n",
        "        features = []\n",
        "        targets = []\n",
        "\n",
        "        for i in range(len(data) - 1):\n",
        "            features.append(data['Numbers'].iloc[i])\n",
        "            targets.append(data['Numbers'].iloc[i + 1])\n",
        "\n",
        "        X = np.array(features)\n",
        "        y = np.array(targets)\n",
        "        return X, y\n"
      ],
      "metadata": {
        "id": "qm2Wias1t91_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def train_decision_tree(self, X, y):\n",
        "        # Train Decision Tree Classifier with hyperparameter tuning\n",
        "        param_grid = {'max_depth': [3, 5, 7, None], 'min_samples_split': [2, 5, 10]}\n",
        "        grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "        grid_search.fit(X, y)\n",
        "        return grid_search.best_estimator_.predict(X)\n"
      ],
      "metadata": {
        "id": "NByjZfLUuD7x"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_random_forest(self, X, y):\n",
        "        # Train Random Forest Classifier with hyperparameter tuning\n",
        "        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, None]}\n",
        "        grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
        "        grid_search.fit(X, y)\n",
        "        return grid_search.best_estimator_.predict(X)\n"
      ],
      "metadata": {
        "id": "dD_fw1eeuKYL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def train_neural_network(self, X, y):\n",
        "        # Train Neural Network\n",
        "        nn_model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000)\n",
        "        nn_model.fit(X, y)\n",
        "        predictions = nn_model.predict(X)\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "Y9vV243SuVpA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def time_series_analysis(self, data):\n",
        "        # Apply ARIMA for time series analysis on Mega Ball\n",
        "        mega_ball_results = data['Mega Ball'].astype(int)\n",
        "        arima_model = ARIMA(mega_ball_results, order=(5, 1, 0))\n",
        "        arima_model_fit = arima_model.fit()\n",
        "        mega_ball_forecast = arima_model_fit.forecast(steps=1)\n",
        "        return mega_ball_forecast.values[0]"
      ],
      "metadata": {
        "id": "SLsJ8Xy8udzA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def clustering(self, data):\n",
        "        # Use K-Means clustering to identify patterns\n",
        "        all_numbers = np.array([num for sublist in data['Numbers'] for num in sublist]).reshape(-1, 1)\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "        kmeans.fit(all_numbers)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(all_numbers, np.zeros_like(all_numbers), c=kmeans.labels_, cmap='viridis', marker='o')\n",
        "        plt.title('K-Means Clustering of Mega Millions Numbers')\n",
        "        plt.xlabel('Mega Millions Numbers')\n",
        "        plt.ylabel('Clusters')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "QATR5RlMuhtj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def genetic_algorithm(self, predictions, historical_data):\n",
        "        # Basic Genetic Algorithm for evolving predictions\n",
        "        population_size = 100\n",
        "        generations = 50"
      ],
      "metadata": {
        "id": "ukiGIbGWumVW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genetic_algorithm(self, predictions, historical_data):\n",
        "    # Basic Genetic Algorithm for evolving predictions\n",
        "    population_size = 100\n",
        "    generations = 50\n",
        "    # Generate initial population\n",
        "    population = [random.sample(range(1, 71), 5) for _ in range(population_size)]  # Mega Millions ranges from 1 to 70\n",
        "\n",
        "    for _ in range(generations):\n",
        "        # Calculate fitness based on historical data\n",
        "        fitness = [self.calculate_fitness(individual, historical_data) for individual in population]\n",
        "\n",
        "        # Selection: choose the best individuals\n",
        "        selected_indices = np.argsort(fitness)[-20:]  # Select top 20 individuals\n",
        "        selected = [population[i] for i in selected_indices]\n",
        "\n",
        "        # Crossover: create new individuals\n",
        "        next_generation = []\n",
        "        while len(next_generation) < population_size:\n",
        "            parent1, parent2 = random.sample(selected, 2)\n",
        "            crossover_point = random.randint(1, 4)\n",
        "            child = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "            next_generation.append(child)\n",
        "\n",
        "        population = next_generation\n",
        "\n",
        "    best_individual = population[np.argmax(fitness)]\n",
        "    return best_individual\n",
        "\n",
        "def calculate_fitness(self, individual, historical_data): # Adjusted indentation to align with genetic_algorithm\n",
        "    # Calculate fitness based on matching historical results\n",
        "    match_count = 0\n",
        "    for _, row in historical_data.iterrows():\n",
        "        if set(individual).intersection(set(row['Numbers'])):\n",
        "            match_count += 1\n",
        "    return match_count  # Higher score for more matches"
      ],
      "metadata": {
        "id": "ZIhe4-F9wZiP"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}